{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSp73Z1LwGVNwdVyusJaAL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install transformers sentencepiece\n","from transformers import AutoTokenizer\n","\n","text = \"Research on Tokenizers and write a section to your final report reflecting on the following questions: What are tokenizers? Why are they important for language modeling and LLMs? What different tokenization algorithms are there and which ones are the most popular ones and why?\"\n","\n","models = {\n","    \"BERT (WordPiece)\": \"bert-base-uncased\",\n","    \"GPT (BPE)\": \"gpt2\",\n","    \"T5 (UnigramLLM via SentencePiece)\": \"t5-small\"\n","}\n","\n","for name, model_name in models.items():\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    tokens = tokenizer.tokenize(text)\n","    print(f\"\\n{name}:\")\n","    print(tokens)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DT4IjukHT359","executionInfo":{"status":"ok","timestamp":1764335697995,"user_tz":-120,"elapsed":7573,"user":{"displayName":"LINYAO DU","userId":"01954601659327523276"}},"outputId":"a453ebf0-fa3f-45f0-dc7d-32b564a123b2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n","\n","BERT (WordPiece):\n","['research', 'on', 'token', '##izer', '##s', 'and', 'write', 'a', 'section', 'to', 'your', 'final', 'report', 'reflecting', 'on', 'the', 'following', 'questions', ':', 'what', 'are', 'token', '##izer', '##s', '?', 'why', 'are', 'they', 'important', 'for', 'language', 'modeling', 'and', 'll', '##ms', '?', 'what', 'different', 'token', '##ization', 'algorithms', 'are', 'there', 'and', 'which', 'ones', 'are', 'the', 'most', 'popular', 'ones', 'and', 'why', '?']\n","\n","GPT (BPE):\n","['Research', 'Ġon', 'ĠToken', 'izers', 'Ġand', 'Ġwrite', 'Ġa', 'Ġsection', 'Ġto', 'Ġyour', 'Ġfinal', 'Ġreport', 'Ġreflecting', 'Ġon', 'Ġthe', 'Ġfollowing', 'Ġquestions', ':', 'ĠWhat', 'Ġare', 'Ġtoken', 'izers', '?', 'ĠWhy', 'Ġare', 'Ġthey', 'Ġimportant', 'Ġfor', 'Ġlanguage', 'Ġmodeling', 'Ġand', 'ĠLL', 'Ms', '?', 'ĠWhat', 'Ġdifferent', 'Ġtoken', 'ization', 'Ġalgorithms', 'Ġare', 'Ġthere', 'Ġand', 'Ġwhich', 'Ġones', 'Ġare', 'Ġthe', 'Ġmost', 'Ġpopular', 'Ġones', 'Ġand', 'Ġwhy', '?']\n","\n","T5 (UnigramLLM via SentencePiece):\n","['▁Research', '▁on', '▁To', 'ken', 'izer', 's', '▁and', '▁write', '▁', 'a', '▁section', '▁to', '▁your', '▁final', '▁report', '▁reflecting', '▁on', '▁the', '▁following', '▁questions', ':', '▁What', '▁are', '▁token', 'izer', 's', '?', '▁Why', '▁are', '▁they', '▁important', '▁for', '▁language', '▁modeling', '▁and', '▁L', 'LM', 's', '?', '▁What', '▁different', '▁token', 'ization', '▁algorithms', '▁are', '▁there', '▁and', '▁which', '▁ones', '▁are', '▁the', '▁most', '▁popular', '▁ones', '▁and', '▁why', '?']\n"]}]}]}